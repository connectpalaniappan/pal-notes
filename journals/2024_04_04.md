---
aliases:
 - <All the good things that happenned today>
tags:
 - nexus/journal_daily
 - people/pal
 - date/2024-04-04
---

Yesterday:: [[Pal_2024_04_03_Wed]] 
Tomorrow:: [[Pal_2024_04_05_Fri]]  
Week:: [[Pal_2024_W14_Q2]]  
Month:: [[Pal_2024_04]]  
Year::  [[Pal_2024]]  
Last year::  [[Pal_2023_04_04_Tue]] 
Quote::  
Error generating daily quote

- # Journal entries 
  1. [https://learn.datadoghq.com/](https://learn.datadoghq.com/) 
  2. is there special agent to monitor JVM and its internals e.g. garbage collections, thread counts, etc.?
  3. [https://www.datadoghq.com/pricing/](https://www.datadoghq.com/pricing/)
  4. it is the same agent, there is specifically a Java tracing library, which is responsible for gathering the JVM [[family-notes/Backup/Pal_Tech_Note/Tech_Notes/systemdesign/concepts/monitoring/metrics|metrics]] [https://docs.datadoghq.com/tracing/metrics/runtime_metrics/java/](https://docs.datadoghq.com/tracing/metrics/runtime_metrics/java/)
  5. here is the more general setup Nicholas shared to use JMXFetch with Datadog to collect the broader range of JMX metrics you've configured to expose: [https://docs.datadoghq.com/integrations/java/?tab=host](https://docs.datadoghq.com/integrations/java/?tab=host)
  6. [https://app.datadoghq.com/profiling/explorer?query=service%3Aplatform-example-java&fromUser=false&my_code=disabled&viz=flame_graph&start=1712247829714&end=1712251429714&paused=false](https://app.datadoghq.com/profiling/explorer?query=service%3Aplatform-example-java&fromUser=false&my_code=disabled&viz=flame_graph&start=1712247829714&end=1712251429714&paused=false)
  7. Spike in latency: [https://app.datadoghq.com/apm/services/tokenization/operations/netty.request/resources?dependencyMap=qson%3A%28data%3A%28telemetrySelection%3Aall_sources%29%2Cversion%3A%210%29&env=pciprod&fromUser=false&groupMapByOperation=null&panels=qson%3A%28data%3A%28%29%2Cversion%3A%210%29&resources=qson%3A%28data%3A%28visible%3A%21t%2Chits%3A%28selected%3Atotal%29%2Cerrors%3A%28selected%3Atotal%29%2Clatency%3A%28selected%3Ap99%29%2CtopN%3A%215%29%2Cversion%3A%211%29&s3BucketDetails=qson%](https://app.datadoghq.com/apm/services/tokenization/operations/netty.request/resources?dependencyMap=qson%3A%28data%3A%28telemetrySelection%3Aall_sources%29%2Cversion%3A%210%29&env=pciprod&fromUser=false&groupMapByOperation=null&panels=qson%3A%28data%3A%28%29%2Cversion%3A%210%29&resources=qson%3A%28data%3A%28visible%3A%21t%2Chits%3A%28selected%3Atotal%29%2Cerrors%3A%28selected%3Atotal%29%2Clatency%3A%28selected%3Ap99%29%2CtopN%3A%215%29%2Cversion%3A%211%29&s3BucketDetails=qson%)
  8. it looks like this trace was responsible for the spike in p99.9 latency, causing an insight in Watchdog. From what I can see so far, it might be an error in pzytranslationapi that caused a long request in the tokenization service: [https://app.datadoghq.com/apm/traces?query=%40_top_level%3A1%20service%3Atokenization%20env%3Apciprod%20operation_name%3Anetty.request%20resource_name%3A%22POST%20%2Fv1%2Ftokens%22&cols=core_service%2Ccore_resource_name%2Clog_duration%2Clog_http.method%2Clog_h](https://app.datadoghq.com/apm/traces?query=%40_top_level%3A1%20service%3Atokenization%20env%3Apciprod%20operation_name%3Anetty.request%20resource_name%3A%22POST%20%2Fv1%2Ftokens%22&cols=core_service%2Ccore_resource_name%2Clog_duration%2Clog_http.method%2Clog_h)
  9. https://app.datadoghq.com/account/login/id/21a22b455 
  10. APM 
  11. Profiling 
  12. Dashboard 
  13.  Powerpack 
  14. Monitor
  1. Threshold monitor 
  1. Metric 
  2. Condition 
  3. Notification 
  2. Anamoly 
  3. Forecast 
  4. Composite monitors 
  15. [https://docs.datadoghq.com/integrations/disk/](https://docs.datadoghq.com/integrations/disk/) 
  16. [https://docs.datadoghq.com/getting_started/tagging/assigning_tags/?tab=noncontainerizedenvironments](https://docs.datadoghq.com/getting_started/tagging/assigning_tags/?tab=noncontainerizedenvironments) 
  17. Can you add a minimum number of requests as a condition?
  18. [https://docs.datadoghq.com/monitors/notify/variables/?tab=is_alert](https://docs.datadoghq.com/monitors/notify/variables/?tab=is_alert)
  19. [https://www.datadoghq.com/blog/tagging-best-practices/#create-automatic-dynamic-alerts-for-your-team](https://www.datadoghq.com/blog/tagging-best-practices/#create-automatic-dynamic-alerts-for-your-team)
  20. [https://www.datadoghq.com/technical-enablement/sessions/](https://www.datadoghq.com/technical-enablement/sessions/)
  21. [https://www.datadoghq.com/blog/autoscale-kubernetes-datadog/](https://www.datadoghq.com/blog/autoscale-kubernetes-datadog/)
  22. DO we need to set up using the DD agents as the metrics server I imagine? it's generally default - the agent function more as a collector rather than a full blown metrics server, so it contains all the logic/scripts to calculate and send metrics to the DD back end
  23. https://app.datadoghq.com/apm/traces?query=%40_top_level%3A1%20env%3Ausprod%20-%40http.path_group%3A%5C%2Foloservice%5C%2Fv1%5C%2F%2A%20&agg_m=%40duration&agg_m_source=base&agg_q=%40http.path_group&agg_q_source=base&agg_t=avg&cols=core_service%2Ccore_resource_name%2Clog_duration%2Clog_http.method%2Clog_http.status_code&fromUser=false&graphType=flamegraph&historicalData=true&messageDisplay=inline&netviz=sent_vol%3A%3A%2Ctcp_r_pct%3A%3A%2Crtt%3A%3A&query_translation_version=v0&shouldShowLegend=tru
  24. you should be able to search by trace_id: for example:  [https://app.datadoghq.com/apm/traces?query=%40_top_level%3A1%20env%3Apciprod%20trace_id%3A606153779276544807%20&cols=core_service%2Ccore_resource_name%2Clog_duration%2Clog_http.method%2Clog_http.status_code&fromUser=false&graphType=flamegraph&historicalData=false&messageDisplay=inline&query_translation_version=v0&shouldShowLegend=true&sort=time&spanType=service-entry&traceQuery=&view=spans&start=1712255651170&end=1712256551170&paused=false(https://app.datadoghq.com/apm/traces?query=%40_top_level%3A1%20env%3Apciprod%20trace_id%3A606153779276544807%20&cols=core_service%2Ccore_resource_name%2Clog_duration%2Clog_http.method%2Clog_http.status_code&fromUser=false&graphType=flamegraph&historicalData=false&messageDisplay=inline&query_translation_version=v0&shouldShowLegend=true&sort=time&spanType=service-entry&traceQuery=&view=spans&start=1712255651170&end=1712256551170&paused=false)
  25. Dynamic instrumentation 
  26. CI Instrumentation runner
  27. [https://www.datadoghq.com/technical-enablement/sessions/](https://www.datadoghq.com/technical-enablement/sessions/)
  28. [https://learn.datadoghq.com/](https://learn.datadoghq.com/)
- # Focus areas
	- [[COS observability]] - COSoncall, Datadog,
	- [[COS Resiliency]] - Netty executors,
	- [[Capability]]
	- [[Architecture guild brainstorming]]
	- [[Work Learning]] - Platform brainstorming, Service mesh, google meeting
	- [[One on One with Manager]]
- # Day planner (Todoist)
  
  > Cue: Look at day planner (Time-based)
  > Craving: Use the headphones to create the flow state, toggl check
  > Response: Start working on a particular task 
  > Reward: 1 hour break (Breathing, meditation, walk, chat with wife, yoga, Stretching, prep food, eat fuel meal, soak in bath tub, short nap, full workout, massage, sauna, journaling, plan day)
- [ ] 06:00 - 06:10 Get out of the bed and come to study room
- [ ] 06:10 - 08:00 [Readwise articles](https://reader.readwise.io) (4 pomodoro)
- [ ] 08:00 - 10:00 Pickleball (or) Walking (or) running (or) Car driving) (4 pomodoro)
	- [ ] Breakfast time
	- [ ] Fitness
	- [ ] Bath
	- [ ] Meditation
- [ ] 10:00 - 13:30 PR review + Meetings + Sprint work + Slack replies (7 pomodoro)
- [ ] 13:30 - 15:00 Lunch time (3 pomodoro)
	- [ ] Pluck rose flowers
	- [ ] pray to god
- [ ] 15:00 - 17:30 Sprint work (5 pomodoro)
- [ ] 17:30 - 18:30 Journaling  (2 pomodoro)
	- [ ] Grateful (people, place)
	- [ ] Highlight
	- [ ] Learnt
	- [ ] Improve
	- [ ] Aliases
	- [ ] Plan for next day tasks
	- [ ] Plan for food(breakfast, lunch, dinner)
	- [ ] Plan for commute
	- [ ] Tempo update
	- [ ] Whatsapp replies
	- [ ] Water the garden
- [ ] 18:30 - 19:30 Dinner time (2 pomodoro)
- [ ] 19:30 - 22:30 Architect Prep or Temple or Pickleball (6 pomodoro)
- [ ] 23:00 - 6:00 Bed time
- # Day spent (Toggl)
  
  > Towards the goal planned weekly. Though enjoy the daily journey towards the goal.  
  
  ```toggl
  LIST
  FROM 2024-04-04 TO 2024-04-04
  GROUP BY PROJECT 
  SORT DESC
  ```
- # Automated tasks 
  Readwise highlights 
  ```dataview 
  table author, elink(URL) as URL
  from #medium
  where file.mday = date(2024-04-04)
  sort file.name asc
  ```
  
  
  
  Generated from: [[Journal_Pal_Daily_Template]]
  Related template: [[Journal_Pal_Weekly_Template]], [[Journal_Pal_Monthly_Template]], [[Journal_Pal_Yearly_Template]]