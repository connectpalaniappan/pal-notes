---
title: How Pinterest Rebuilt Their Logging Stack
full Title: How Pinterest Rebuilt Their Logging Stack
author: Quastor
URL: 
published date: 2024-04-09
category: articles
source: reader
tags: [medium/articles, author/Quastor, reader/reader, date/2024-04-14, area/reader]
created: 2024-04-14
assignedTo: people/pal
priority: P4
work: document
---
author:: [[Quastor]]
note:: 
source:: [[reader]]
url:: 
image_url:: [articles image URL](https://readwise-assets.s3.amazonaws.com/static/images/article3.5c705a01b476.png)
category:: [[articles]]
date:: [[2024-04-14]]
last_highlighted_date:: [[2024-04-14]]
published_date:: [[2024-04-09]]
summary:: Pinterest revamped their logging system to enhance observability by utilizing key-value pairs for flexibility and real-time visualization through OpenSearch. The new architecture involves storing data in Kafka, processing with Logstash, and integrating with AWS OpenSearch for analytics. The updated system allows developers to gain insights on app performance and codebase visibility, fostering better monitoring and alerting capabilities.


![rw-book-cover](https://readwise-assets.s3.amazonaws.com/static/images/article3.5c705a01b476.png)

## Highlights
### id706837552
[[2024-04-14]] 14:35
> Logs are time stamped records of discrete events/messages that are generated by the various applications, services and components in your system.
> They’re meant to provide a *qualitative* view of the backend’s behavior and can typically be split into
> • **Application Logs** - Messages logged by your server code, databases, etc.
> • **System Logs** - Generated by systems-level components like the operating system, disk errors, hardware devices, etc.
> • **Network Logs** - Generated by routers, load balancers, firewalls, etc. They provide information about network activity like packet drops, connection status, traffic flow and more.
> Logs are commonly in plaintext, but they can also be in a structured format like JSON. They’ll be stored in a database like Elasticsearch
> The issue with just using logs is that they can be extremely noisy and it’s hard to extrapolate any higher-level meaning of the state of your system out of the logs.
> Incorporating metrics into your toolkit helps you solve this.


### id706837722
[[2024-04-14]] 14:38
> Metrics provide a *quantitative* view of your backend around factors like response times, error rates, throughput, resource utilization and more. They’re commonly stored in a time series database.
> They’re amenable to statistical modeling and prediction. Calculating averages, percentiles, correlation and more with metrics make them particularly useful for understanding the behavior of your system over some period of time.
> The shortcoming of both metrics and logs is that they’re scoped to an individual component/system. If you want to figure out what happened across your entire system during the lifetime of a request that traversed multiple services/components, you’ll have to do some additional work (joining together logs/metrics from multiple components).
> This is where Distributed Tracing comes in.


### id706837911
[[2024-04-14]] 14:39
> **Tracing**
> Distributed traces allow you to track and understand how a single request flows through multiple components/services in your system.
> To implement this, you identify specific points in your backend where you have some fork in execution flow or a hop across network/process boundaries. This can be a call to another microservice, a database query, a cache lookup, etc.
> Then, you assign each request that comes into your system a [UUID](https://link.mail.beehiiv.com/ss/c/u001.GaP25kixWOTuE1E3XPYxBYaNyUGZyVKJhuXIbGlJOOLUJIjV6ub92uyIcESFk25X3CVMHQgJXdifMJDkeKSOdYowqyZ0Zgk3zIa1HFpx1G7xN-jA_F1KvLz80eHipQTEJ4tHl5iVFSrkYyvNnAJem-JtrdOM4PbRnZsVpQP9l50PaS5WUU3GmaX4Qfz2IaDJzDBiUBqrhF71Jp2_3vxBcrrtS5k6y3nZSSFYmvvZxWQ/45d/PALeBuGFS9KF_JDdR1nunQ/h12/h001.4K-W_igY7Sjf6-noOnmKRQrzZayuHUgsz-D6rztSJ3c) (unique ID) so you can keep track of it. You add instrumentation to each of these specific points in your backend so you can track when the request enters/leaves (the OpenTelemetry project calls this [Context Propagation](https://link.mail.beehiiv.com/ss/c/u001.D0tvvj5znpCmCaUIlCn_q5dksXDp_lvtRnMiIrjTSFaXaE4TQOVpZ61a4vlhF7hUyigrIGfWWYNhdF-Z4rvwHV_mEfQwsMLLBe9U_0em8Y_EkT7G-ilZLrHMfa8omJ2OtGT7G84gfBgPVDjGfDj8EX-R9We6RZBY9ni1Q44RvJkiDSBoiEoXzWXeQIszljKEdbzqtJz0lzwNZFaXKmfBJZ0DnomOdScqwlQeHq9qzE8/45d/PALeBuGFS9KF_JDdR1nunQ/h13/h001.dEfvk0myqKOgaKZphxcTOTzAxUtSyouHEL6k-VAeUxY)).
> You can analyze this data with an open source system like Jaeger or Zipkin.
> If you’d like to learn more about implementing Traces, you can read about how DoorDash used OpenTelemetry [here](https://link.mail.beehiiv.com/ss/c/u001.LUZYrxblx92g0_IcD8eBHeJtYbs4ot4RMUOF7cLoZ2AZCkb92022WdMGaqH8_GwN6xoBjnDJ0GLYL9fo4jcZLuqNBEYX2syAcsl9M7puNKpW_Gx3h-Afrp-O_-m_TZOst0VLkrZY0iIpSMSSqr-SHZp1ROGLF3olxs04uFzlQX57FKnMNfai9Oz7uOEnu64KG0QnQGJvoi0QVpw4CYoPqcvlIqQ4dgYFRx50AnQz1U5j1ZGD7qNaaRUwBGahSbm0HTzOmc16BMR9FfTN8_vRPvPaXz_r3P_3UeEsky5Bs5g/45d/PALeBuGFS9KF_JDdR1nunQ/h14/h001.5Gt0MwT2lDa5RIox1tdU1ddkecnx4aKU6Mgbh3bUeso).


### id706838474
[[2024-04-14]] 14:41
> **Real Time** - They made it easy to set up real-time alerting with custom metrics based on the logs

- [n] Interesting to note, you can create custom metrics from logs  * [View Highlight](https://read.readwise.io/read/01hvf228p7881828syz044j26t)


